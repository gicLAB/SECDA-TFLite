#!/bin/bash

# Documentation
# What is this script for?
# This script is used to run the benchmark suite on the board and process the results
# It runs the benchmarks in the configs.sh arrays
# It also runs the inference diff binary to verify the correctness of the accelerator
# It also runs the benchmark binary to collect the performance numbers

# How to use this script?
# ./run_collect.sh [process_on_fpga] [skip_inf_diff]
# process_on_fpga - 0 or 1 - 0 to not process the results on the fpga and 1 to process the results on the fpga
# skip_inf_diff - 0 or 1 - 0 to run the inference diff binary and 1 to skip running the inference diff binary

# During each benchmark run, the script will load the bitstream if the hardware is different from the previous run
# It will also clear the cache if the model is different from the previous run

# It generates a file called commands.txt which contains all the commands that were run on the board
# It also generates a file called tmp/${runname}_id.txt which contains the output of the inference diff binary
# It also generates a file called tmp/${runname}_bm.txt which contains the output of the benchmark binary
# It also generates a file called tmp/${runname}_prf.csv which contains the acc_profile generated by the delegate
# It also generates a file called tmp/${runname}_layer.csv which contains the layer profile generated by the benchmark binary

# Do not run this script directly, run secda_benchmark_suite.sh instead

source configs.sh
process_on_fpga=0
prev_failed=0
skip_inf_diff=0
collect_power=0
test_run=0
# prev_hw=${hw_array[0]}
prev_hw=""
prev_model=""

# Check if we are processing locally
if [ $# -eq 1 ]; then
  process_on_fpga=$1
fi

if [ $# -eq 2 ]; then
  process_on_fpga=$1
  skip_inf_diff=$2
fi

if [ $# -eq 3 ]; then
  process_on_fpga=$1
  skip_inf_diff=$2
  collect_power=$3
fi

if [ $# -eq 4 ]; then
  process_on_fpga=$1
  skip_inf_diff=$2
  collect_power=$3
  test_run=$4
fi

echo "Configurations"
echo "--------------"
echo "process_on_fpga=${process_on_fpga}"
echo "skip_inf_diff=${skip_inf_diff}"
echo "collect_power=${collect_power}"
echo "test_run=${test_run}"
echo "-----------------------------------------------------------"

length=${#hw_array[@]}
# create a file to store commands
rm -f ./commands.txt
touch ./commands.txt
rm -f ./runs.csv
touch ./runs.csv

# delete the tmp directory
rm -rf ./tmp
mkdir ./tmp

function ctrl_c() {
  echo "Exiting"
  exit 1
}

trap ctrl_c INT

bitstream_dir=£{board_dir}/bitstreams
scripts_dir=£{board_dir}/scripts
board_user=£{board_user}

bench_dir=£{board_dir}/benchmark_suite
model_dir=${bench_dir}/models
bin_dir=${bench_dir}/bins

for ((i = 0; i < length; i++)); do
  index=$((i + 1))
  HW=${hw_array[$i]}
  MODEL=${model_array[$i]}
  THREAD=${thread_array[$i]}
  NUM_RUN=${num_run_array[$i]}
  VERSION=${version_array[$i]}
  DEL_VERSION=${del_version_array[$i]}
  DEL=${del_array[$i]}

  runname=${HW}_${VERSION}_${DEL}_${DEL_VERSION}_${MODEL}_${THREAD}_${NUM_RUN}
  echo "========================================================================"
  echo "${runname} ${index}/${length}"
  echo "========================================================================"

  #if prev_hw was different then load base bitstream and sleep 1 second
  if [ ${prev_failed} -eq 1 ] || [ "${prev_hw_version}" != "${HW}_${VERSION}" ]; then
    echo "Loading bitstream ${HW}_${VERSION}.bit"
    echo sudo python3 ${scripts_dir}/load_bitstream.py ${bitstream_dir}/${HW}_${VERSION}.bit -q >>commands.txt
    sudo python3 ${scripts_dir}/load_bitstream.py ${bitstream_dir}/${HW}_${VERSION}.bit -q
    if [ $? -ne 0 ]; then prev_failed=1 && echo "Load bitstream failed ${bitstream_dir}/${HW}_${VERSION}.bit" && continue; fi
  fi

  if [ "${prev_model}" != "${MODEL}" ]; then
    echo "Clearing cache"
    sudo sh -c "/bin/echo 3 > /proc/sys/vm/drop_caches" # Clear cache
  fi

  prev_failed=0
  prev_hw=${HW}
  prev_hw_version=${HW}_${VERSION}
  prev_model=${MODEL}

  rm -f ./tmp/${runname}_*.txt
  rm -f ./prf.csv
  rm -f ./layer.csv

  usedel="--use_${DEL}=true"
  if [ ${HW} == "CPU" ]; then usedel=""; fi

  if [ "${test_run}" -eq 1 ]; then
    sudo timeout --foreground 60 ${bin_dir}/id_${DEL}_${DEL_VERSION} --num_runs=${NUM_RUN} --model_file=£{model_dir}/${MODEL}.tflite --num_interpreter_threads=${THREAD} ${usedel}
    if [ $? -ne 0 ]; then
      echo "id failed"
      echo sudo timeout --foreground 60 ${bin_dir}/id_${DEL}_${DEL_VERSION} --num_runs=${NUM_RUN} --model_file=£{model_dir}/${MODEL}.tflite --num_interpreter_threads=${THREAD} ${usedel}
      prev_failed=1
      continue
    fi
    continue
  fi

  valid=1
  # if hardware is not CPU and skip_inf_diff is not set
  if [ ${HW} != "CPU" ] && [ "${skip_inf_diff}" -eq 0 ]; then {
    # Running inference diff binary
    echo "Running inference diff"
    echo sudo timeout --foreground 60 ${bin_dir}/id_${DEL}_${DEL_VERSION} --num_runs=1 --model_file=${model_dir}/${MODEL}.tflite --num_interpreter_threads=${THREAD} ${usedel} >>commands.txt
    sudo timeout --foreground 60 ${bin_dir}/id_${DEL}_${DEL_VERSION} --num_runs=1 --model_file=${model_dir}/${MODEL}.tflite --num_interpreter_threads=${THREAD} ${usedel} >tmp/${runname}_id.txt 2>&1
    if [ $? -ne 0 ]; then
      echo "id failed"
      echo sudo timeout --foreground 60 ${bin_dir}/id_${DEL}_${DEL_VERSION} --num_runs=1 --model_file=${model_dir}/${MODEL}.tflite --num_interpreter_threads=${THREAD} ${usedel}
      prev_failed=1
      continue
    fi
    # # Check verify correctness of accelerator
    python3 ${scripts_dir}/check_valid.py tmp/${runname}_id.txt
    if [ $? -ne 0 ]; then valid=0 && echo "Correctness check failed" && echo sudo python3 ${scripts_dir}/load_bitstream.py ${bitstream_dir}/${HW}_${VERSION}.bit -q && echo sudo timeout --foreground 60 ${bin_dir}/id_${DEL}_${DEL_VERSION} --num_runs=1 --model_file=${model_dir}/${MODEL}.tflite --num_interpreter_threads=${THREAD} ${usedel}; fi
  }; fi

  if [ ${test_run} -eq 1 ]; then valid=0; fi

  # Run benchmark
  if [ ${valid} -eq 1 ]; then
    if [ ${collect_power} -eq 1 ]; then
      # Run benchmark with power collection
      echo sudo ${bin_dir}/bm_${DEL}_${DEL_VERSION} --max_secs=600 --num_runs=${NUM_RUN} --graph=${model_dir}/${MODEL}.tflite --num_threads=${THREAD} --enable_op_profiling=true --profiling_output_csv_file="layer.csv" --collect_power=true ${usedel} >>commands.txt
      sudo ${bin_dir}/bm_${DEL}_${DEL_VERSION} --max_secs=600 --num_runs=${NUM_RUN} --graph=${model_dir}/${MODEL}.tflite --num_threads=${THREAD} --collect_power=true --enable_op_profiling=true --profiling_output_csv_file="layer.csv" ${usedel} 2>/dev/null | tee tmp/${runname}_bm.txt
      rtime=$(cat runtime.txt)
      echo "${MODEL},${HW},${VERSION},${DEL},${DEL_VERSION},${THREAD},${NUM_RUN},${rtime}" >>runs.csv
      if [ $? -ne 0 ]; then
        echo "bm failed"
        echo sudo ${bin_dir}/bm_${DEL}_${DEL_VERSION} --max_secs=600 --num_runs=${NUM_RUN} --graph=${model_dir}/${MODEL}.tflite --num_threads=${THREAD} --collect_power=true ${usedel}
        prev_failed=1
        continue
      fi
    else
      # Run benchmark without power collection
      echo "Running benchmark"
      echo sudo ${bin_dir}/bm_${DEL}_${DEL_VERSION} --max_secs=600 --num_runs=${NUM_RUN} --graph=${model_dir}/${MODEL}.tflite --num_threads=${THREAD} --enable_op_profiling=true --profiling_output_csv_file="layer.csv" ${usedel} >>commands.txt
      sudo ${bin_dir}/bm_${DEL}_${DEL_VERSION} --max_secs=600 --num_runs=${NUM_RUN} --graph=${model_dir}/${MODEL}.tflite --num_threads=${THREAD} --enable_op_profiling=true --profiling_output_csv_file="layer.csv" ${usedel} >tmp/${runname}_bm.txt 2>&1
      rtime=$(cat runtime.txt)
      echo "${MODEL},${HW},${VERSION},${DEL},${DEL_VERSION},${THREAD},${NUM_RUN},${rtime}" >>runs.csv
      if [ $? -ne 0 ]; then
        echo "bm failed"
        echo sudo ${bin_dir}/bm_${DEL}_${DEL_VERSION} --max_secs=600 --num_runs=${NUM_RUN} --graph=${model_dir}/${MODEL}.tflite --num_threads=${THREAD} --enable_op_profiling=true --profiling_output_csv_file="layer.csv" ${usedel}
        prev_failed=1
        continue
      fi
    fi

    if [ -e prf.csv ]; then
      mv -f prf.csv tmp/${runname}_prf.csv
    fi
    if [ -e layer.csv ]; then
      mv -f layer.csv tmp/${runname}_layer.csv
    fi
  fi

done # HW

if [ -e runs.csv ]; then
  mv -f runs.csv tmp/runs.csv
fi

rm -f sds_trace_data.dat
rm -f layer.csv
rm -f prf.csv
rm -f runtime.txt
